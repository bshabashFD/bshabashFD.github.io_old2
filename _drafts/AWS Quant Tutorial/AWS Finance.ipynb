{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Quantitative Trading \n",
    "\n",
    "## Employing Web Scrapping, AWS, and ML to Find Good Trades\n",
    "\n",
    "The idea of quantitative trading is the use of algorithms to make more informed and less passionate decisions regarding trades. There are many different methodologies which can be employed for quantitative trading. However, in this post I'd like to focus on the idea of building an end to end pipeline which will attempt to produce future predictions on price changes. \n",
    "\n",
    "Often times, a novice data scientist will be concerned with the process of building and optimizing a model, as well as producing buy-in to their ideas through the use of a convincing narrative and powerful visualizations. These steps are critical, but are not exhaustive. A full, simple, end-to-end framework will be concerned with these steps, but also with obtaining data, finding the right platform for the analysis to run, and performing all these steps in a reproducible way (in case a more senior data scientist would like to reproduce them).\n",
    "\n",
    "This set of posts will break down the workflow into three major parts:\n",
    "\n",
    "1. Obtain the data, and prepare it for modeling\n",
    "2. Run a set of models on Amazon Web Service (AWS) and collect the best one\n",
    "3. Prepare a simple summary of all observations during step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Obtain the data\n",
    "\n",
    "Since we are interested in historic data for stocks there are several available options. Quandl is a service which can provide daily stock data (in minute to minute intervals), but it costs money. For this post I will opt out for the free option, and employ Yahoo Finance.\n",
    "\n",
    "Navigating to the Yahoo Finance website you will be greeted with the following page, and a download button within it. \n",
    "\n",
    "![png](Yahoo_Finance1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link from the download link will look like this<br>\n",
    "https://query1.finance.yahoo.com/v7/finance/download/AAPL?period1=1420095600&period2=1577862000&interval=1d&events=history&crumb=X68TFb4PiMR\n",
    "\n",
    "There are four important parameters embedded in this link: \n",
    "\n",
    "* `AAPL` - the stock we are interested in, in this case it is AAPL (Apple Inc)\n",
    "* `period1=1420095600` - a timestamp of the start period (this timestamp is actually Jan 1st, 2015, 7am)\n",
    "* `period2=1577862000` - another timestamp for the end period (this one is Jan 1st, 2020, 7am)\n",
    "* `crumb=X68TFb4PiMR` - this is an authentication token which makes the link valid, no request will work without it\n",
    "\n",
    "The authentication token is quite important since that token will allow us to to query remotely. If we run the following bash code. Let's assume for now we have some way of obtaining that code (it expires after some time). We need to query the address and get back the response.\n",
    "\n",
    "If we use Python's requests library, we can run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "STOCK_ID = \"AAPL\"\n",
    "start_time = \"1420095600\"\n",
    "end_time = \"1577862000\"\n",
    "auth_token = \"X68TFb4PiMR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'https://query1.finance.yahoo.com/v7/finance/download/{STOCK_ID}\\\n",
    "?period1={start_time}\\\n",
    "&period2={end_time}&interval=1d&events=history\\\n",
    "&crumb={auth_token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>111.389999</td>\n",
       "      <td>111.440002</td>\n",
       "      <td>107.349998</td>\n",
       "      <td>109.330002</td>\n",
       "      <td>100.454300</td>\n",
       "      <td>53204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>108.290001</td>\n",
       "      <td>108.650002</td>\n",
       "      <td>105.410004</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>97.624336</td>\n",
       "      <td>64285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>106.540001</td>\n",
       "      <td>107.430000</td>\n",
       "      <td>104.629997</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>97.633545</td>\n",
       "      <td>65797100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>107.199997</td>\n",
       "      <td>108.199997</td>\n",
       "      <td>106.699997</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>99.002556</td>\n",
       "      <td>40105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>109.230003</td>\n",
       "      <td>112.150002</td>\n",
       "      <td>108.699997</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>102.806480</td>\n",
       "      <td>59364500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2015-01-02  111.389999  111.440002  107.349998  109.330002  100.454300   \n",
       "1  2015-01-05  108.290001  108.650002  105.410004  106.250000   97.624336   \n",
       "2  2015-01-06  106.540001  107.430000  104.629997  106.260002   97.633545   \n",
       "3  2015-01-07  107.199997  108.199997  106.699997  107.750000   99.002556   \n",
       "4  2015-01-08  109.230003  112.150002  108.699997  111.889999  102.806480   \n",
       "\n",
       "     Volume  \n",
       "0  53204600  \n",
       "1  64285500  \n",
       "2  65797100  \n",
       "3  40105900  \n",
       "4  59364500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (r.status_code == 200):\n",
    "    # the response content is a bytes type so we need to turn it into a string\n",
    "    csv_content = r.content.decode(\"utf-8\")\n",
    "    the_data = StringIO(csv_content)\n",
    "    stock_df = pd.read_csv(the_data)\n",
    "    display(stock_df.head()) # this only works in a Jupyter notebook\n",
    "else:\n",
    "    print(\"Request failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this code gets the job done, it's so far very specific to a unique use scenario. It only gets the data for AAPL and only does so within a certain date range (and only works for a limited time given the authentication code).\n",
    "\n",
    "We should probably wrap this into a function so we can make it slightly more versatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def get_stock_data(STOCK_ID, start_time, end_time, auth_code):\n",
    "    request_string = f'https://query1.finance.yahoo.com/v7/finance/download/{STOCK_ID}?period1={start_time}&period2={end_time}&interval=1d&events=history&crumb={auth_token}'\n",
    "    r = requests.post(request_string)\n",
    "    \n",
    "    if (r.status_code == 200):\n",
    "        # the response content is a bytes type so we need to turn it into a string\n",
    "        csv_content = r.content.decode(\"utf-8\")\n",
    "        the_data = StringIO(csv_content)\n",
    "        stock_df = pd.read_csv(the_data)\n",
    "        return stock_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Start and End Dates\n",
    "\n",
    "Let's start with the easy part, the start and end times. We can get today's date quite easily, and then find the date five years back. We can then easily convert both into epoch time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578013295\n",
      "1420246895\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "end_time = datetime.now() \n",
    "start_time = datetime.now() - relativedelta(years=5)\n",
    "\n",
    "end_time = round(datetime.timestamp(end_time))\n",
    "start_time = round(datetime.timestamp(start_time))\n",
    "\n",
    "\n",
    "print(end_time)\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = get_stock_data(\"AAPL\", start_time, end_time, auth_token)\n",
    "type(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Authentication Token\n",
    "\n",
    "Now the next part, obtaining the authentication token. The token appears as part of the link on the webpage of Yahoo Finance for a given stock. This means I can navigate to any given stock page and grab an authentication code from the HTML. Let's select an asset we're quite certain will always be available, perhaps the S&P500.\n",
    "\n",
    "Searching for that asset on the Yahoo Finance page we see the URL is the following:<br>\n",
    "`https://ca.finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_request = requests.get(\"https://ca.finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html id=\"atomic\" class=\"NoJs featurephone\" lang=\"en-CA\"><head prefix=\"og: http://ogp\n"
     ]
    }
   ],
   "source": [
    "result = yahoo_request.content.decode(\"utf-8\")\n",
    "print(result[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a response and after searching through, using the technological wonder that is the find feature in text editors, we find our token (crumb) as `\"CrumbStore\":{\"crumb\":\"Z4FrXH54dXl\"}`. We can check the new crumb works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_auth_token = \"Z4FrXH54dXl\"\n",
    "my_df = get_stock_data(\"AAPL\", start_time, end_time, new_auth_token)\n",
    "type(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed it works, now we can use the regex magic to find our crumb in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_string = yahoo_request.content.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mKVz6ki0NcX\n"
     ]
    }
   ],
   "source": [
    "all_crumbs = re.findall('\"CrumbStore\":{\"crumb\":\"\\w+\"',response_string)\n",
    "if (len(all_crumbs) > 0):\n",
    "    my_crumb_string = all_crumbs[0].replace(\"\\\"CrumbStore\\\":{\\\"crumb\\\":\", \"\").replace(\"\\\"\", \"\")\n",
    "print(my_crumb_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should pack that into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_crumb_token(asset=\"%5EGSPC\"):\n",
    "    yahoo_request = requests.get(f'https://ca.finance.yahoo.com/quote/{asset}/history?p={asset}')\n",
    "    response_string = yahoo_request.content.decode(\"utf-8\")\n",
    "    \n",
    "    # Search for our crumb store\n",
    "    all_crumbs = re.findall('\"CrumbStore\":{\"crumb\":\"\\w+\"',response_string)\n",
    "    if (len(all_crumbs) > 0):\n",
    "        my_crumb_string = all_crumbs[0].replace(\"\\\"CrumbStore\\\":{\\\"crumb\\\":\", \"\").replace(\"\\\"\", \"\")\n",
    "    \n",
    "        return my_crumb_string\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have our basic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_crumb_token(asset=\"%5EGSPC\"):\n",
    "    yahoo_request = requests.get(f'https://ca.finance.yahoo.com/quote/{asset}/history?p={asset}')\n",
    "    response_string = yahoo_request.content.decode(\"utf-8\")\n",
    "    \n",
    "    # Search for our crumb store\n",
    "    all_crumbs = re.findall('\"CrumbStore\":{\"crumb\":\"\\w+\"',response_string)\n",
    "    if (len(all_crumbs) > 0):\n",
    "        my_crumb_string = all_crumbs[0].replace(\"\\\"CrumbStore\\\":{\\\"crumb\\\":\", \"\").replace(\"\\\"\", \"\")\n",
    "    \n",
    "        return my_crumb_string\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_stock_data(STOCK_ID, start_time, end_time, auth_code):\n",
    "    request_string = f'https://query1.finance.yahoo.com/v7/finance/download/{STOCK_ID}?period1={start_time}&period2={end_time}&interval=1d&events=history&crumb={auth_token}'\n",
    "    r = requests.post(request_string)\n",
    "    \n",
    "    if (r.status_code == 200):\n",
    "        # the response content is a bytes type so we need to turn it into a string\n",
    "        csv_content = r.content.decode(\"utf-8\")\n",
    "        the_data = StringIO(csv_content)\n",
    "        stock_df = pd.read_csv(the_data)\n",
    "        return stock_df\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def get_start_and_end_dates(difference=5):\n",
    "    end_date = datetime.now()\n",
    "    start_date = datetime.now() - relativedelta(years=difference)\n",
    "\n",
    "    end_date = round(datetime.timestamp(end_date))\n",
    "    start_date = round(datetime.timestamp(start_date))\n",
    "    \n",
    "    return start_date, end_date\n",
    "\n",
    "start_date, end_date = get_start_and_end_dates()\n",
    "auth_token = get_crumb_token()\n",
    "\n",
    "STOCK_ID = \"AAPL\"\n",
    "\n",
    "stock_df = get_stock_data(STOCK_ID, start_date, end_date, auth_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>108.290001</td>\n",
       "      <td>108.650002</td>\n",
       "      <td>105.410004</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>97.624336</td>\n",
       "      <td>64285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>106.540001</td>\n",
       "      <td>107.430000</td>\n",
       "      <td>104.629997</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>97.633545</td>\n",
       "      <td>65797100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>107.199997</td>\n",
       "      <td>108.199997</td>\n",
       "      <td>106.699997</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>99.002556</td>\n",
       "      <td>40105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>109.230003</td>\n",
       "      <td>112.150002</td>\n",
       "      <td>108.699997</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>102.806480</td>\n",
       "      <td>59364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>112.669998</td>\n",
       "      <td>113.250000</td>\n",
       "      <td>110.209999</td>\n",
       "      <td>112.010002</td>\n",
       "      <td>102.916725</td>\n",
       "      <td>53699500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2015-01-05  108.290001  108.650002  105.410004  106.250000   97.624336   \n",
       "1  2015-01-06  106.540001  107.430000  104.629997  106.260002   97.633545   \n",
       "2  2015-01-07  107.199997  108.199997  106.699997  107.750000   99.002556   \n",
       "3  2015-01-08  109.230003  112.150002  108.699997  111.889999  102.806480   \n",
       "4  2015-01-09  112.669998  113.250000  110.209999  112.010002  102.916725   \n",
       "\n",
       "     Volume  \n",
       "0  64285500  \n",
       "1  65797100  \n",
       "2  40105900  \n",
       "3  59364500  \n",
       "4  53699500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stock_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece for this portion of the code is to put all the code we've written into a script which accepts our stock id as a command line argument, and also saves the dataframe into a path also provided by a command line. We are going to add much more documentation and split some of our functions to create a more manageable code base.\n",
    "\n",
    "We will call the script `obtain_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "##################################################################\n",
    "def attempt_getting_token(asset, attempt):\n",
    "    '''\n",
    "    A single attempt at getting a crumb authentication token.\n",
    "    Sends a request to Yahoo finance and uses regex to find\n",
    "    an instance of an authentication token.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    asset (str) -   the asset (stock code) whose page is visited on \n",
    "                    Yahoo Finance\n",
    "    attempt (int) - the attempt number, how many times was this\n",
    "                    action attempted\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    an authentication token (string) if successful, None otherwise\n",
    "    '''\n",
    "    logging.info(f'Attempt {attempt+1}: Getting token from Yahoo Finance')\n",
    "\n",
    "    # Get the request and response\n",
    "    yahoo_request = requests.get(f'https://ca.finance.yahoo.com/quote/{asset}/history?p={asset}')\n",
    "    response_string = yahoo_request.content.decode(\"utf-8\")\n",
    "\n",
    "    # Search for our token (crumb store) with regex\n",
    "    all_tokens = re.findall(r'\"CrumbStore\":{\"crumb\":\"\\w+\"',response_string)\n",
    "    if (len(all_tokens) > 0):\n",
    "        # Replace everything that isn't the crumb with empty strings\n",
    "        my_token_string = all_tokens[0].replace(\"\\\"CrumbStore\\\":{\\\"crumb\\\":\", \"\").replace(\"\\\"\", \"\")\n",
    "    \n",
    "        logging.info(f'Token found {my_token_string}')\n",
    "        return my_token_string\n",
    "    else:\n",
    "        return None\n",
    "##################################################################\n",
    "def get_crumb_token(asset=\"%5EGSPC\"):\n",
    "    '''\n",
    "    Attempts getting an authentication token 10 times using attempt_getting_crumb(asset, attempt)\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    asset (string, default S&P500) -    the asset (stock code) whose page is visited on \n",
    "                                        Yahoo Finance\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    an authentication token (string) if successful, None otherwise\n",
    "    '''\n",
    "    logging.info('Attmepting to get token')\n",
    "    my_token_string = None\n",
    "    attempts = 0\n",
    "    while (attempts < 10) and (my_token_string is None):\n",
    "        \n",
    "        # Try and get the authentication token\n",
    "        my_token_string = attempt_getting_token(asset, attempts)\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "        # If unsuccessful, sleep so you don't bombard the website\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Return the appropriate result and log the process\n",
    "    if (my_token_string is None):\n",
    "        logging.warning('Token not found')\n",
    "        return None\n",
    "    else:\n",
    "        logging.info(f'Token found {my_token_string}')\n",
    "        return my_token_string\n",
    "\n",
    "##################################################################\n",
    "def get_stock_data(STOCK_ID, start_time, end_time, auth_code):\n",
    "    ''' \n",
    "    Gets the stock data for the request stock within the range\n",
    "    specified by [start_time] and [end_time]\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    STOCK_ID (string) - The asset for which data is requested\n",
    "                        (e.g. AAPL, MSFT)\n",
    "    start_time (int) -  The start time as an epoch time (e.g. 1420229214)\n",
    "    end_time (int) -    The end time as an epoch time\n",
    "    auth_code (string) -The authentication code used to make \n",
    "                        the request valid for Yahoo Finance\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    a pandas.core.DataFrame of the stock historic\n",
    "    data if successful, None otherwise\n",
    "    '''\n",
    "    logging.info(f'Obtaining data for symbol {STOCK_ID}')\n",
    "\n",
    "    # Grab the data\n",
    "    request_string = f'https://query1.finance.yahoo.com/v7/finance/download/{STOCK_ID}?period1={start_time}&period2={end_time}&interval=1d&events=history&crumb={auth_token}'\n",
    "    r = requests.post(request_string)\n",
    "    \n",
    "    # If the code is okay we can process the data\n",
    "    if (r.status_code == 200):\n",
    "        # the response content is a bytes type so we need to turn it into a string\n",
    "        csv_content = r.content.decode(\"utf-8\")\n",
    "\n",
    "        # feed the data to pandas\n",
    "        the_data = StringIO(csv_content)\n",
    "        stock_df = pd.read_csv(the_data)\n",
    "\n",
    "        logging.info('Stock data found')\n",
    "        return stock_df\n",
    "    else:\n",
    "        logging.warning('Stock data not found')\n",
    "        return None\n",
    "    \n",
    "\n",
    "##################################################################\n",
    "def get_start_and_end_dates(difference=5):\n",
    "    ''' \n",
    "    Calculates start and end dates for our requests.\n",
    "    End date is the current day while start date \n",
    "    is [difference] years ago\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    difference (int, default 5) -   The difference between start date \n",
    "                                    and end date in years.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    The start and end dates, both as datime objects\n",
    "    '''\n",
    "    logging.info(\"Calculating start and end dates\")\n",
    "    end_date = datetime.now()\n",
    "    start_date = datetime.now() - relativedelta(years=difference)\n",
    "\n",
    "    # remove convert to epoch time and remove fractional component\n",
    "    end_date = round(datetime.timestamp(end_date))\n",
    "    start_date = round(datetime.timestamp(start_date))\n",
    "    \n",
    "    logging.info(f'Start date as as {start_date} and end date as {end_date}')\n",
    "    return start_date, end_date\n",
    "\n",
    "##################################################################\n",
    "def parse_command_line_arguments():\n",
    "    '''\n",
    "    Parses the command line arguments that come in\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    [args], a namespace collection which contains the \n",
    "    variables [.output_directory] and [.stock_id]\n",
    "    \n",
    "    [args.stock_id] is a string containing the stock symbol\n",
    "    that is requested\n",
    "\n",
    "    [args.output_directory] contains a path to a directory or\n",
    "    an empty string (current directory) if not provided\n",
    "    by the user\n",
    "    '''\n",
    "    logging.info(\"Parsing command line arguments\")\n",
    "\n",
    "    # Make a parser and parse the arguments\n",
    "    parser = argparse.ArgumentParser(description='Obtain Data From Yahoo Finance.')\n",
    "    parser.add_argument('stock_id', help='The symbol of the asset to retrieve')\n",
    "    parser.add_argument('--output_directory', help='The output directory for the data in .csv format')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # If our output directory is empty, make it an empty string.\n",
    "    # Otherwise, append the appropriate seperator to it\n",
    "    if not (args.output_directory):\n",
    "        args.output_directory = \"\"\n",
    "    else:\n",
    "        args.output_directory += os.path.sep\n",
    "    \n",
    "    logging.info(\"Command line arguments parsed\")\n",
    "    return args\n",
    "##################################################################\n",
    "def output_stock_df_to_csv(stock_df, output_directory):\n",
    "    '''\n",
    "    Outputs the dataframe containing the stock data\n",
    "    to the specified output directory\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    stock_df (pandas.core.DataFrame) -  The dataframe storing the stock\n",
    "                                        data\n",
    "    output_directory (string) -         The output directory where to\n",
    "                                        store the data\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    None\n",
    "    '''\n",
    "    logging.info('Outputting dataframe to csv file')\n",
    "    if (stock_df is not None):        \n",
    "        stock_df.to_csv(output_directory)\n",
    "        logging.info(f'data written to {output_directory}')\n",
    "    else:\n",
    "        logging.warning('data not written')\n",
    "##################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize a log file\n",
    "    logging.basicConfig(filename='pipeline.log', filemode=\"w\", level=logging.DEBUG)\n",
    "\n",
    "    if not (sys.version[:3] >= \"3.6\"):\n",
    "        logging.error(\"Incorrect Python version found, requires 3.6+, found \"+sys.version)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get our command line arumgnets\n",
    "    args = parse_command_line_arguments()\n",
    "\n",
    "    # Get the start and end dates\n",
    "    start_date, end_date = get_start_and_end_dates()\n",
    "\n",
    "    # Get authentication token\n",
    "    auth_token = get_crumb_token()\n",
    "\n",
    "    # If a toekn was obtained we can get the stock data and write it to file\n",
    "    if (auth_token is not None):\n",
    "        STOCK_ID = args.stock_id\n",
    "\n",
    "        stock_df = get_stock_data(STOCK_ID, start_date, end_date, auth_token)\n",
    "\n",
    "        output_directory = args.output_directory+STOCK_ID+\".csv\"\n",
    "        output_stock_df_to_csv(stock_df, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've added quite a bit of docstrings and other documentation in case we will want to change something later.\n",
    "\n",
    "Now we can call this script as:\n",
    "\n",
    "`python obtain_data.py MSFT /usr/boris/destination`\n",
    "\n",
    "And have it obtain the data for Microsoft (MSFT) and write the result to a local csv file in /usr/boris/destination/MSFT.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing the Script on S3\n",
    "\n",
    "We want to have AWS computing instances being able to run this script. One thing we can do is simply use SSH to transfer the files unto the instance, but later on we would like to have our instances be set up, run, and torn down automatically without us having to do much, so we will place this script in AWS's S3 storage bucket. This will make it so our future computing instances could access the file easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create an S3 bucket (1) and give it a useful and descriptive name. Once created we can see it in the S3 dashboard (2).\n",
    "\n",
    "![png](S3_bucket.png)\n",
    "\n",
    "and then we upload the script into the bucket so that our AWS instances can access the script and its functionality\n",
    "\n",
    "![png](upload_file.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
