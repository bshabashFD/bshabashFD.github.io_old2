{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Quantitative Trading \n",
    "\n",
    "In a previous post we've explored the use of Python as well as the requests library in order to obtain historic financial data from an online source (in our case, Yahoo Finance). We've developed a Python script to do that for us and uploaded it to an S3 bucket on AWS for safekeeping and easy access from other AWS services. In this post we will explore the next step, setting up a workflow which creates a processing server for us, trains a model on our data in that server, and then removes the server when we're done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Run a set of models on Amazon Web Service (AWS)\n",
    "\n",
    "AWS's pricing model is \"pay as you use,\" which means we can create a server, do some data processing on it, and then tear it down, and we'll only pay for the amount of time we've used the server for. Furthermore, we are going to use a client library for spinning up the server (fancy term for creating a server) and tearing it down called awscli (AWS Client). Much of the workflow presented here is taken from [a post by Brent Lemieux](https://towardsdatascience.com/production-data-processing-with-apache-spark-96a58dfd3fe7?) and I strongly encourage you to check out that post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure our client application\n",
    "\n",
    "First we will install and configure awscli. Once installed we can test that it works\n",
    "\n",
    "```\n",
    "aws2 -- version\n",
    ">>> aws-cli/2.0.0dev2 Python/3.7.5 Windows/10 botocore/2.0.0dev1\n",
    "```\n",
    "\n",
    "Then we configure it. In configuring awsclie [this page](https://docs.aws.amazon.com/general/latest/gr/rande.html) might be useful for the default region selection.\n",
    "\n",
    "Once we are configured, we can employ awscli and spin up our servers. Reading [Brent Lemieux's post](https://towardsdatascience.com/production-data-processing-with-apache-spark-96a58dfd3fe7?), he describes how to create a bootstrap file which will initialize the server for us. You will notice we need to install packages such as pandas and matplotlib into the server since it comes with some bare minimum of python packages.\n",
    "\n",
    "Let me show you how to create an empty environment to first make sure this all works before deploying a bootstrap into AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the instance, you must first run\n",
    "\n",
    "`aws2 emr create-default-roles`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bootstrap script you need to add\n",
    "`alias python=/usr/bin/python3`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
